{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af88d27b-c48c-494e-bedb-d19ecc05acfe",
   "metadata": {},
   "source": [
    "# <b><u>PREPROCESSING II: SENTENCE TO VECTOR and WORD TO VECTOR</u></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b6df509-dd4d-4427-a29e-de62689aadfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import sklearn\n",
    "import copy\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bcba4db-2b26-475c-92a3-bfe1c58027db",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def processing1(sentence):\n",
    "    sentence = re.sub('[^a-zA-Z0-9\\s]', '', sentence) # remove punctuations and any kind of symbols\n",
    "    sentence = sentence.lower() # convert everything to same case to avoid redundancy due to mixed cases\n",
    "    sentence = sentence.split() # list of words\n",
    "    sentence = [word for word in sentence if word not in set(nltk.corpus.stopwords.words('english')) ] # remove unimportant stopwords\n",
    "    sentence = [lemmatizer.lemmatize(word) for word in sentence ] # lemmatize to base words\n",
    "    sentence = ' '.join(sentence) # back to sentence from processed list of words\n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1aa64469-5699-4a7c-b545-ccadf6d3a9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = '''\n",
    "I have three visions for India. \n",
    "In 3000 years of our history, people from all over the world have come and invaded us, captured our lands, conquered our minds. \n",
    "From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British, the French, the Dutch, all of them came and looted us, took over what was ours. \n",
    "Yet we have not done this to any other nation. We have not conquered anyone. \n",
    "We have not grabbed their land, their culture, their history and tried to enforce our way of life on them.\n",
    "Why? Because we respect the freedom of others.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd54d9b-cf95-46f3-a937-d16e341ce7a7",
   "metadata": {},
   "source": [
    "## <b><u>Extracting sentences and Preprocessing I (cleanup): </u></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fab651eb-c21f-4b76-85c4-ce5e5af185ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Preprocessed Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>three vision india</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000 year history people world come invaded u captured land conquered mind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alexander onwards greek turk mogul portuguese british french dutch came looted u took</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yet done nation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>conquered anyone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>grabbed land culture history tried enforce way life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>respect freedom others</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   Preprocessed Sentence\n",
       "0                                                                     three vision india\n",
       "1             3000 year history people world come invaded u captured land conquered mind\n",
       "2  alexander onwards greek turk mogul portuguese british french dutch came looted u took\n",
       "3                                                                        yet done nation\n",
       "4                                                                       conquered anyone\n",
       "5                                    grabbed land culture history tried enforce way life\n",
       "6                                                                                       \n",
       "7                                                                 respect freedom others"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract all sentences from paragraph. Each sentence will be turned into vector having some specific features (unique words).\n",
    "sentences = nltk.sent_tokenize(paragraph)\n",
    "\n",
    "# Processing 1\n",
    "sentences = [processing1(sentence) for sentence in sentences]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"Preprocessed Sentence\"] = sentences\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f042155-ad51-4bc3-8a16-f4b198ab7de0",
   "metadata": {},
   "source": [
    "## <b><u>BAG OF WORDS (sentence to vector)</u></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cba388-f250-444a-87fd-5385a9849d5d",
   "metadata": {},
   "source": [
    "In bag of words technique, we **consider WORDS as FEATURES (each unique word present in the entire corpus(collection of sentences) is treated as a unique feature)** <br>\n",
    "Each sentence is represented by a vector **based on the \"FREQUENCY\" of each of the unique words(features) in the sentence**\n",
    "<br><br>\n",
    "For Example: <br>\n",
    "Let `corpus = [ \"orange is a fruit of orange colour\", \"carrot is a vegetable of orange colour\" ]` <br>\n",
    "After cleanup and preprocessing 1, <br>\n",
    "`corpus = [ \"orange fruit orange colour\", \"carrot vegetable orange colour\" ]` <br>\n",
    "So; **unique words** in sorted order are: `[ \"carrot\", \"colour\", \"fruit\", \"orange\", \"vegetable\" ]` <br>\n",
    "So; after vectorizing using **bag of words(frequency based)** technique; the vectors corresponding to the sentences in the preprocessed corpus will be: <br>\n",
    "`vectors = [ [ 0 1 1 2 0 ], [ 1 1 0 1 1 ] ]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a507fa3-6bfa-4326-9e12-c9846741131e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features(Words) are:\n",
      "\n",
      "['3000' 'alexander' 'anyone' 'british' 'came' 'captured' 'come'\n",
      " 'conquered' 'culture' 'done' 'dutch' 'enforce' 'freedom' 'french'\n",
      " 'grabbed' 'greek' 'history' 'india' 'invaded' 'land' 'life' 'looted'\n",
      " 'mind' 'mogul' 'nation' 'onwards' 'others' 'people' 'portuguese'\n",
      " 'respect' 'three' 'took' 'tried' 'turk' 'vision' 'way' 'world' 'year'\n",
      " 'yet']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Preprocessed Sentence</th>\n",
       "      <th>Bag of words Vector Representation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>three vision india</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000 year history people world come invaded u captured land conquered mind</td>\n",
       "      <td>[1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alexander onwards greek turk mogul portuguese british french dutch came looted u took</td>\n",
       "      <td>[0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yet done nation</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>conquered anyone</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>grabbed land culture history tried enforce way life</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>respect freedom others</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   Preprocessed Sentence  \\\n",
       "0                                                                     three vision india   \n",
       "1             3000 year history people world come invaded u captured land conquered mind   \n",
       "2  alexander onwards greek turk mogul portuguese british french dutch came looted u took   \n",
       "3                                                                        yet done nation   \n",
       "4                                                                       conquered anyone   \n",
       "5                                    grabbed land culture history tried enforce way life   \n",
       "6                                                                                          \n",
       "7                                                                 respect freedom others   \n",
       "\n",
       "                                                                                      Bag of words Vector Representation  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0]  \n",
       "1  [1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0]  \n",
       "2  [0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0]  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]  \n",
       "4  [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "5  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0]  \n",
       "6  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "7  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting sentences to vectors using Bag Of Words strategy\n",
    "vectorizer = sklearn.feature_extraction.text.CountVectorizer()\n",
    "vectors_bow = vectorizer.fit_transform(sentences).toarray().tolist()\n",
    "\n",
    "print(\"Features(Words) are:\\n\")\n",
    "print(vectorizer.get_feature_names_out())\n",
    "\n",
    "df[\"Bag of words Vector Representation\"] = vectors_bow\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451cc6c8-e609-48d0-b799-174cec582477",
   "metadata": {},
   "source": [
    "## <b><u>Term Frequency - Inverse Document Frequency (TF-IDF)</u></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3534417f-84b8-4fb4-b84c-342b825bd8d4",
   "metadata": {},
   "source": [
    "In tf-idf technique also, we **consider WORDS as FEATURES (each unique word present in the entire corpus(collection of sentences) is treated as a unique feature)** <br>\n",
    "Each sentence is represented by a vector **based on the \"TF Score * IDF Score\" value of each of the unique words(features) present in the sentence** <br>\n",
    "<br>\n",
    "**Term Frequency(TF) of a word W in a sentence S = (Frequency of W in S / Total number of words in S)** <br><br>\n",
    "**Inverse Docment Frequency(IDF) of a word W in a corpus(collection of sentences) C = log(Total number of sentences in C / Number of sentences which contain W atleast once)**\n",
    "<br><br>\n",
    "The **TF Score * IDF Score** value helps in **giving the more importent words more weightage and less important words less weightage**. <br>\n",
    "<br>\n",
    "For Example: <br>\n",
    "Let `corpus = [ \"orange is a fruit of orange colour\", \"carrot is a vegetable of orange colour\" ]` <br>\n",
    "After cleanup and preprocessing 1, <br>\n",
    "`corpus = [ \"orange fruit orange colour\", \"carrot vegetable orange colour\" ]` <br>\n",
    "So; **unique words** in sorted order are: `[ \"carrot\", \"colour\", \"fruit\", \"orange\", \"vegetable\" ]` <br>\n",
    "So; the **TF vectors** corresponding to the sentences in the preprocessed corpus will be: <br>\n",
    "`tf_vectors = [ [ 0 1/4 1/4 2/4 0 ], [ 1/4 1/4 0 1/4 1/4 ] ] = [ [ 0 0.25 0.25 0.5 0 ], [ 0.25 0.25 0 0.25 0.25 ] ]` <br>\n",
    "`idf_vector = [ log(2/1) log(2/2) log(2/1) log(2/2) log(2/1) ] = [ 0.3 0 0.3 0 0.3 ]` <br>\n",
    "`tf_idf_vectors = [ [ (0*0.3) (0.25*0) (0.25*0.3) (0.5*0) (0*0.3) ], [ (0.25*0.3) (0.25*0) (0*0.3) (0.25*0) (0.25*0.3) ] ] = [ [ 0 0 0.075 0 0 ], [ 0.075 0 0 0 0.075 ] ]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "035a1a7d-23ba-4abf-bab8-60e0a8db0bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features(Words) are:\n",
      "\n",
      "['3000' 'alexander' 'anyone' 'british' 'came' 'captured' 'come'\n",
      " 'conquered' 'culture' 'done' 'dutch' 'enforce' 'freedom' 'french'\n",
      " 'grabbed' 'greek' 'history' 'india' 'invaded' 'land' 'life' 'looted'\n",
      " 'mind' 'mogul' 'nation' 'onwards' 'others' 'people' 'portuguese'\n",
      " 'respect' 'three' 'took' 'tried' 'turk' 'vision' 'way' 'world' 'year'\n",
      " 'yet']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Preprocessed Sentence</th>\n",
       "      <th>Bag of words Vector Representation</th>\n",
       "      <th>TF-IDF Vector Representation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>three vision india</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5773502691896258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5773502691896258, 0.0, 0.0, 0.0, 0.5773502691896258, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000 year history people world come invaded u captured land conquered mind</td>\n",
       "      <td>[1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0]</td>\n",
       "      <td>[0.31454746818160906, 0.0, 0.0, 0.0, 0.0, 0.31454746818160906, 0.31454746818160906, 0.2636153271241494, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2636153271241494, 0.0, 0.31454746818160906, 0.2636153271241494, 0.0, 0.0, 0.31454746818160906, 0.0, 0.0, 0.0, 0.0, 0.31454746818160906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.31454746818160906, 0.31454746818160906, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alexander onwards greek turk mogul portuguese british french dutch came looted u took</td>\n",
       "      <td>[0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0.0, 0.2886751345948129, 0.0, 0.2886751345948129, 0.2886751345948129, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2886751345948129, 0.0, 0.0, 0.2886751345948129, 0.0, 0.2886751345948129, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2886751345948129, 0.0, 0.2886751345948129, 0.0, 0.2886751345948129, 0.0, 0.0, 0.2886751345948129, 0.0, 0.0, 0.2886751345948129, 0.0, 0.2886751345948129, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yet done nation</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5773502691896258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5773502691896258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5773502691896258]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>conquered anyone</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0.0, 0.0, 0.7664298449085388, 0.0, 0.0, 0.0, 0.0, 0.6423280258820045, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>grabbed land culture history tried enforce way life</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.36748939521121393, 0.0, 0.0, 0.36748939521121393, 0.0, 0.0, 0.36748939521121393, 0.0, 0.30798479381600735, 0.0, 0.0, 0.30798479381600735, 0.36748939521121393, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.36748939521121393, 0.0, 0.0, 0.36748939521121393, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>respect freedom others</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5773502691896258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5773502691896258, 0.0, 0.0, 0.5773502691896258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   Preprocessed Sentence  \\\n",
       "0                                                                     three vision india   \n",
       "1             3000 year history people world come invaded u captured land conquered mind   \n",
       "2  alexander onwards greek turk mogul portuguese british french dutch came looted u took   \n",
       "3                                                                        yet done nation   \n",
       "4                                                                       conquered anyone   \n",
       "5                                    grabbed land culture history tried enforce way life   \n",
       "6                                                                                          \n",
       "7                                                                 respect freedom others   \n",
       "\n",
       "                                                                                      Bag of words Vector Representation  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0]   \n",
       "1  [1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0]   \n",
       "2  [0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0]   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]   \n",
       "4  [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "5  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0]   \n",
       "6  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "7  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                              TF-IDF Vector Representation  \n",
       "0                                                                                                                                         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5773502691896258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5773502691896258, 0.0, 0.0, 0.0, 0.5773502691896258, 0.0, 0.0, 0.0, 0.0]  \n",
       "1         [0.31454746818160906, 0.0, 0.0, 0.0, 0.0, 0.31454746818160906, 0.31454746818160906, 0.2636153271241494, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2636153271241494, 0.0, 0.31454746818160906, 0.2636153271241494, 0.0, 0.0, 0.31454746818160906, 0.0, 0.0, 0.0, 0.0, 0.31454746818160906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.31454746818160906, 0.31454746818160906, 0.0]  \n",
       "2  [0.0, 0.2886751345948129, 0.0, 0.2886751345948129, 0.2886751345948129, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2886751345948129, 0.0, 0.0, 0.2886751345948129, 0.0, 0.2886751345948129, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2886751345948129, 0.0, 0.2886751345948129, 0.0, 0.2886751345948129, 0.0, 0.0, 0.2886751345948129, 0.0, 0.0, 0.2886751345948129, 0.0, 0.2886751345948129, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "3                                                                                                                                         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5773502691896258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5773502691896258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5773502691896258]  \n",
       "4                                                                                                                                                        [0.0, 0.0, 0.7664298449085388, 0.0, 0.0, 0.0, 0.0, 0.6423280258820045, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "5                                                      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.36748939521121393, 0.0, 0.0, 0.36748939521121393, 0.0, 0.0, 0.36748939521121393, 0.0, 0.30798479381600735, 0.0, 0.0, 0.30798479381600735, 0.36748939521121393, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.36748939521121393, 0.0, 0.0, 0.36748939521121393, 0.0, 0.0, 0.0]  \n",
       "6                                                                                                                                                                                      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "7                                                                                                                                         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5773502691896258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5773502691896258, 0.0, 0.0, 0.5773502691896258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting sentences to vectors using TF-IDF strategy\n",
    "vectorizer = sklearn.feature_extraction.text.TfidfVectorizer()\n",
    "vectors_tfidf = vectorizer.fit_transform(sentences).toarray().tolist()\n",
    "\n",
    "print(\"Features(Words) are:\\n\")\n",
    "print(vectorizer.get_feature_names_out())\n",
    "\n",
    "df[\"TF-IDF Vector Representation\"] = vectors_tfidf\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "ml-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
